{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "lastEditStatus": {
   "notebookId": "qf7yjgcp66uvpgt4amkr",
   "authorId": "279826730347",
   "authorName": "SNOWMAN",
   "authorEmail": "stephen.dickson@snowflake.com",
   "sessionId": "a89a7968-fa4e-4ec9-bc4f-bdb970543d80",
   "lastEditTime": 1764906545256
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "2503c7d4-e458-4b3c-b880-8f9ff7d3170f",
   "metadata": {
    "language": "python",
    "name": "cell30",
    "collapsed": false,
    "codeCollapsed": true
   },
   "outputs": [],
   "source": "import streamlit as st\nst.image(\"Snowflake_Logo.svg\", width=300)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "# Origence Intelligence Agent - ML Models\n\n**Training 3 Machine Learning Models for Credit Union Lending**\n\nThis notebook trains 3 ML models for the Origence Intelligence Agent:\n1. **LOAN_DEFAULT_PREDICTOR** - Predicts loan default risk (4 classes)\n2. **LOAN_APPROVAL_PREDICTOR** - Predicts loan approval likelihood (3 classes)\n3. **FRAUD_DETECTION_MODEL** - Detects fraudulent applications (3 classes)\n\n---\n\n## Prerequisites\n- Database: `ORIGENCE_INTELLIGENCE`\n- Schema: `ML_MODELS`\n- Feature views created (V_LOAN_DEFAULT_FEATURES, V_LOAN_APPROVAL_FEATURES, V_FRAUD_DETECTION_FEATURES)\n- Packages: `snowflake-ml-python`, `scikit-learn`, `pandas`",
   "id": "ce110000-1111-2222-3333-ffffff000000"
  },
  {
   "cell_type": "code",
   "id": "c384a474-b01e-4864-98a8-7bcb32ea2809",
   "metadata": {
    "language": "python",
    "name": "cell29"
   },
   "outputs": [],
   "source": "import os\nprint(os.listdir('.'))  # Lists all files in current directory",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell2"
   },
   "source": [
    "## Setup and Imports"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000001"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell3",
    "language": "python"
   },
   "outputs": [],
   "source": "# Import required libraries\nfrom snowflake.snowpark import Session\nfrom snowflake.ml.modeling.ensemble import RandomForestClassifier\nfrom snowflake.ml.modeling.linear_model import LogisticRegression\nfrom snowflake.ml.modeling.preprocessing import OneHotEncoder, StandardScaler\nfrom snowflake.ml.modeling.pipeline import Pipeline\nfrom snowflake.ml.registry import Registry\nimport pandas as pd\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\nprint(\"✅ Libraries imported successfully\")",
   "id": "ce110000-1111-2222-3333-ffffff000002"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell4",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Get current session\n",
    "session = Session.builder.getOrCreate()\n",
    "\n",
    "# Set context\n",
    "session.use_database(\"ORIGENCE_INTELLIGENCE\")\n",
    "session.use_schema(\"ML_MODELS\")\n",
    "session.use_warehouse(\"ORIGENCE_WH\")\n",
    "\n",
    "print(\"✅ Session configured\")\n",
    "print(f\"Database: {session.get_current_database()}\")\n",
    "print(f\"Schema: {session.get_current_schema()}\")\n",
    "print(f\"Warehouse: {session.get_current_warehouse()}\")"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000003"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell5",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Initialize Model Registry\n",
    "registry = Registry(\n",
    "    session=session,\n",
    "    database_name=\"ORIGENCE_INTELLIGENCE\",\n",
    "    schema_name=\"ML_MODELS\"\n",
    ")\n",
    "\n",
    "print(\"✅ Model Registry initialized\")"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000004"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell6"
   },
   "source": [
    "---\n",
    "## Model 1: Loan Default Risk Predictor\n",
    "\n",
    "**Objective**: Predict likelihood of loan default  \n",
    "**Labels**: 0=Low Risk, 1=Medium Risk, 2=High Risk, 3=Critical Risk  \n",
    "**Algorithm**: Random Forest Classifier  \n",
    "**Features**: Loan amount, term, interest rate, credit score, DTI, LTV, payment history"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000005"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell7",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Load loan default feature data\n",
    "default_df = session.table(\"ORIGENCE_INTELLIGENCE.ANALYTICS.V_LOAN_DEFAULT_FEATURES\")\n",
    "\n",
    "print(f\"✅ Loaded {default_df.count()} records for default prediction\")\n",
    "default_df.show(5)"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000006"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell8",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "train_default, test_default = default_df.random_split([0.8, 0.2], seed=42)\n",
    "\n",
    "# Drop ID columns not needed for training\n",
    "train_default = train_default.drop(\"LOAN_ID\")\n",
    "test_default = test_default.drop(\"LOAN_ID\")\n",
    "\n",
    "print(f\"Training set: {train_default.count()} records\")\n",
    "print(f\"Test set: {test_default.count()} records\")"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000007"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell9",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Create FAST default prediction pipeline - optimized for <10s execution\n",
    "# Using simpler model: fewer trees, shallow depth, no scaling\n",
    "default_pipeline = Pipeline([\n",
    "    (\"Encoder\", OneHotEncoder(\n",
    "        input_cols=[\"LOAN_TYPE\"],\n",
    "        output_cols=[\"LOAN_TYPE_ENC\"],\n",
    "        drop_input_cols=True,\n",
    "        handle_unknown=\"ignore\"\n",
    "    )),\n",
    "    (\"Classifier\", RandomForestClassifier(\n",
    "        label_cols=[\"DEFAULT_RISK_LABEL\"],\n",
    "        output_cols=[\"PREDICTED_RISK\"],\n",
    "        n_estimators=3,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"✅ Default prediction pipeline created (optimized for speed)\")"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000008"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell10",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Train the default prediction model\n",
    "print(\"Training default prediction model...\")\n",
    "default_pipeline.fit(train_default)\n",
    "print(\"✅ Default prediction model trained\")"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000009"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell11",
    "language": "python"
   },
   "outputs": [],
   "source": "# Evaluate model on test set\ntest_predictions = default_pipeline.predict(test_default)\ntest_results = test_predictions.select(\"DEFAULT_RISK_LABEL\", \"PREDICTED_RISK\").to_pandas()\n\nfrom sklearn.metrics import accuracy_score, classification_report\naccuracy = accuracy_score(test_results['DEFAULT_RISK_LABEL'], test_results['PREDICTED_RISK'])\n\nprint(f\"Test Accuracy: {accuracy:.3f}\")\nprint(\"\\nClassification Report:\")\nprint(classification_report(\n    test_results['DEFAULT_RISK_LABEL'], \n    test_results['PREDICTED_RISK']\n))",
   "id": "ce110000-1111-2222-3333-ffffff000010"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell12",
    "language": "python"
   },
   "outputs": [],
   "source": "# Register model in Model Registry\n# Drop label column from sample data - model signature should only include features\nsample_data = train_default.drop(\"DEFAULT_RISK_LABEL\").limit(100)\n\nregistry.log_model(\n    model=default_pipeline,\n    model_name=\"LOAN_DEFAULT_PREDICTOR\",\n    target_platforms=['WAREHOUSE'],\n    sample_input_data=sample_data,\n    comment=\"Predicts loan default risk with 4 risk levels (Low/Medium/High/Critical)\"\n)\n\nprint(\"✅ LOAN_DEFAULT_PREDICTOR registered in Model Registry\")",
   "id": "ce110000-1111-2222-3333-ffffff000011"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell13"
   },
   "source": [
    "---\n",
    "## Model 2: Loan Approval Predictor\n",
    "\n",
    "**Objective**: Predict loan application approval likelihood  \n",
    "**Labels**: 0=Likely Deny, 1=Needs Review, 2=Likely Approve  \n",
    "**Algorithm**: Logistic Regression  \n",
    "**Features**: Credit score, income, DTI, employment, LTV, collateral"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000012"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell14",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Load loan approval feature data\n",
    "approval_df = session.table(\"ORIGENCE_INTELLIGENCE.ANALYTICS.V_LOAN_APPROVAL_FEATURES\")\n",
    "\n",
    "print(f\"✅ Loaded {approval_df.count()} records for approval prediction\")\n",
    "approval_df.show(5)"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000013"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell15",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_approval, test_approval = approval_df.random_split([0.8, 0.2], seed=42)\n",
    "\n",
    "train_approval = train_approval.drop(\"APPLICATION_ID\")\n",
    "test_approval = test_approval.drop(\"APPLICATION_ID\")\n",
    "\n",
    "print(f\"Training set: {train_approval.count()} records\")\n",
    "print(f\"Test set: {test_approval.count()} records\")"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000014"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell16",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Create FAST approval prediction pipeline - optimized for <10s execution\n",
    "# Using LogisticRegression with fewer iterations, no scaling\n",
    "approval_pipeline = Pipeline([\n",
    "    (\"Encoder\", OneHotEncoder(\n",
    "        input_cols=[\"LOAN_TYPE\"],\n",
    "        output_cols=[\"LOAN_TYPE_ENC\"],\n",
    "        drop_input_cols=True,\n",
    "        handle_unknown=\"ignore\"\n",
    "    )),\n",
    "    (\"Classifier\", LogisticRegression(\n",
    "        label_cols=[\"APPROVAL_LABEL\"],\n",
    "        output_cols=[\"PREDICTED_APPROVAL\"],\n",
    "        max_iter=100\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"✅ Approval prediction pipeline created (optimized for speed)\")"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000015"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell17",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Train the approval prediction model\n",
    "print(\"Training approval prediction model...\")\n",
    "approval_pipeline.fit(train_approval)\n",
    "print(\"✅ Approval prediction model trained\")"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000016"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell18",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "test_predictions = approval_pipeline.predict(test_approval)\n",
    "test_results = test_predictions.select(\"APPROVAL_LABEL\", \"PREDICTED_APPROVAL\").to_pandas()\n",
    "\n",
    "accuracy = accuracy_score(test_results['APPROVAL_LABEL'], test_results['PREDICTED_APPROVAL'])\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    test_results['APPROVAL_LABEL'], \n",
    "    test_results['PREDICTED_APPROVAL'],\n",
    "    target_names=['Likely Deny', 'Needs Review', 'Likely Approve']\n",
    "))"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000017"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell19",
    "language": "python"
   },
   "outputs": [],
   "source": "# Register model\n# Drop label column from sample data - model signature should only include features\nsample_data = train_approval.drop(\"APPROVAL_LABEL\").limit(100)\n\nregistry.log_model(\n    model=approval_pipeline,\n    model_name=\"LOAN_APPROVAL_PREDICTOR\",\n    target_platforms=['WAREHOUSE'],\n    sample_input_data=sample_data,\n    comment=\"Predicts loan approval likelihood with 3 outcomes (Deny/Review/Approve)\"\n)\n\nprint(\"✅ LOAN_APPROVAL_PREDICTOR registered in Model Registry\")",
   "id": "ce110000-1111-2222-3333-ffffff000018"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell20"
   },
   "source": [
    "---\n",
    "## Model 3: Fraud Detection Model\n",
    "\n",
    "**Objective**: Detect potentially fraudulent loan applications  \n",
    "**Labels**: 0=Clean, 1=Suspicious, 2=High Risk  \n",
    "**Algorithm**: Random Forest Classifier  \n",
    "**Features**: Application velocity, income verification, credit anomalies, DTI flags"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000019"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell21",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Load fraud detection feature data\n",
    "fraud_df = session.table(\"ORIGENCE_INTELLIGENCE.ANALYTICS.V_FRAUD_DETECTION_FEATURES\")\n",
    "\n",
    "print(f\"✅ Loaded {fraud_df.count()} records for fraud detection\")\n",
    "fraud_df.show(5)"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000020"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell22",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_fraud, test_fraud = fraud_df.random_split([0.8, 0.2], seed=42)\n",
    "\n",
    "train_fraud = train_fraud.drop(\"APPLICATION_ID\")\n",
    "test_fraud = test_fraud.drop(\"APPLICATION_ID\")\n",
    "\n",
    "print(f\"Training set: {train_fraud.count()} records\")\n",
    "print(f\"Test set: {test_fraud.count()} records\")"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000021"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell23",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Create FAST fraud detection pipeline - optimized for <10s execution\n",
    "# Using simpler RandomForest: fewer trees, shallow depth, no scaling\n",
    "fraud_pipeline = Pipeline([\n",
    "    (\"Encoder\", OneHotEncoder(\n",
    "        input_cols=[\"LOAN_TYPE\"],\n",
    "        output_cols=[\"LOAN_TYPE_ENC\"],\n",
    "        drop_input_cols=True,\n",
    "        handle_unknown=\"ignore\"\n",
    "    )),\n",
    "    (\"Classifier\", RandomForestClassifier(\n",
    "        label_cols=[\"FRAUD_RISK_LABEL\"],\n",
    "        output_cols=[\"PREDICTED_FRAUD_RISK\"],\n",
    "        n_estimators=3,\n",
    "        max_depth=3,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "print(\"✅ Fraud detection pipeline created (optimized for speed)\")"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000022"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell24",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Train the fraud detection model\n",
    "print(\"Training fraud detection model...\")\n",
    "fraud_pipeline.fit(train_fraud)\n",
    "print(\"✅ Fraud detection model trained\")"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000023"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell25",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "test_predictions = fraud_pipeline.predict(test_fraud)\n",
    "test_results = test_predictions.select(\"FRAUD_RISK_LABEL\", \"PREDICTED_FRAUD_RISK\").to_pandas()\n",
    "\n",
    "accuracy = accuracy_score(test_results['FRAUD_RISK_LABEL'], test_results['PREDICTED_FRAUD_RISK'])\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.3f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    test_results['FRAUD_RISK_LABEL'], \n",
    "    test_results['PREDICTED_FRAUD_RISK'],\n",
    "    target_names=['Clean', 'Suspicious', 'High Risk']\n",
    "))"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000024"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell26",
    "language": "python"
   },
   "outputs": [],
   "source": "# Register model\n# Drop label column from sample data - model signature should only include features\nsample_data = train_fraud.drop(\"FRAUD_RISK_LABEL\").limit(100)\n\nregistry.log_model(\n    model=fraud_pipeline,\n    model_name=\"FRAUD_DETECTION_MODEL\",\n    target_platforms=['WAREHOUSE'],\n    sample_input_data=sample_data,\n    comment=\"Detects fraudulent applications with 3 risk levels (Clean/Suspicious/High Risk)\"\n)\n\nprint(\"✅ FRAUD_DETECTION_MODEL registered in Model Registry\")",
   "id": "ce110000-1111-2222-3333-ffffff000025"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "name": "cell27"
   },
   "source": [
    "---\n",
    "## Summary and Verification"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000026"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cell28",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# List all registered models\n",
    "models = session.sql(\"SHOW MODELS IN SCHEMA ML_MODELS\").collect()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REGISTERED MODELS\")\n",
    "print(\"=\"*80)\n",
    "for model in models:\n",
    "    print(f\"✅ {model['name']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL TRAINING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n3 ML models successfully trained and registered:\")\n",
    "print(\"1. LOAN_DEFAULT_PREDICTOR - Predicts default risk (4 classes)\")\n",
    "print(\"2. LOAN_APPROVAL_PREDICTOR - Predicts approval likelihood (3 classes)\")\n",
    "print(\"3. FRAUD_DETECTION_MODEL - Detects fraud risk (3 classes)\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Run origence_07_model_wrapper_functions.sql to create SQL procedures\")\n",
    "print(\"2. Run origence_08_create_intelligence_agent.sql to configure agent\")\n",
    "print(\"3. Test agent with sample questions from origence_questions.md\")"
   ],
   "id": "ce110000-1111-2222-3333-ffffff000027"
  }
 ]
}
